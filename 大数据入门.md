### 大数据入门引导

#### 1. 分而治之

分治是一种被广泛应用的有效方法，它的基本思想是**把最初的问题分解成若干子问题，然后逐个解决各个子问题的基础上得到原始问题的解**。

算法思想：

~~~
将要求解的较大规模的问题分割成k个更小规模的子问题。
对这k个子问题分别求解。如果子问题的规模仍然不够小，则再划分为k个子问题，如此递归的进行下去，直到问题规模足够小，很容易求出其解为止。
将求出的小规模的问题的解合并为一个更大规模的问题的解，自底向上逐步求出原来问题的解。
分治的设计思想是，将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。
~~~



![fen_er_zhi_zhi](.\image\fen_er_zhi_zhi.jpg)

适用条件：

~~~
分治所能解决的问题具备以下特征：

该问题的规模缩小到一定的程度就可以容易地解决；
该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质
利用该问题分解出的子问题的解可以合并为该问题的解；
该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子问题。
~~~

分治思想三个阶段：

~~~
设计过程分为三个阶段：

Divide：整个问题划分为多个子问题
Conquer：求解各子问题(递归调用正设计的算法)
Merge：合并子问题的解, 形成原始问题的解
~~~



#### 2. MapReduce

mapReduce分析作业流程：输入分片(input split)、map阶段、combiner阶段、shuffle阶段、reduce阶段。

1. input split：在map计算之前，程序会根据输入文件计算split，每个input split针对一个map任务。input split存储的并非是数据本身，而是一个分片长度和一个记录数据的位置的数组。

2. map阶段：即执行map函数。

3. combiner阶段：这是一个可选择的函数，实质上是一种reduce操作。combiner是map的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作。

4. shuffle阶段：指从map输出开始，包括系统执行排序即传送map输出到reduce作为输入的过程。另外针对map输出的key进行排序又叫sort阶段。map端shuffle，简单来说就是利用combiner对数据进行预排序，利用内存缓冲区来完成。reduce端的shuffle包括复制数据和归并数据，最终产生一个reduce输入文件。shuffle过程有许多可调优的参数来提高MapReduce的性能，其总原则就是给shuffle过程尽量多的内存空间。

5. reduce阶段：即执行reduce函数并存到hdfs文件系统中。

详细流程图如下

![mapReduce](.\image\mapReduce.jpg)

#### 3. Spark

##### spark 和 MapReduce的差异

Spark 延续了MapReduce 的设计思路：对数据的计算也分为Map 和Reduce 两类。但不同的是，一个Spark 任务并不止包含一个Map 和一个Reduce，而是由一系列的Map、Reduce构成。这样，计算的中间结果可以高效地转给下一个计算步骤，提高算法性能。虽然Spark 的改进看似很小，但实验结果显示，它的算法性能相比MapReduce 提高了10～100 倍。

**1，交换数据的方式**

MR 多使用hdfs做数据交换，多节点会带来网络IO压力；Spark多是基于本地磁盘做数据交换。

**2，执行单元**

MR 的task的执行单元是进程，进程的创建销毁的开销较大；Spark的task执行单元是线程，开销较小。

**3，缓存**

MR 基本上没有使用缓存，读取效率低；Spark是用Buffle KV做缓存，很适合算法场景的多次迭代计算，也可以了解一下“钨丝计划”及向量化查询。

**4，shuffle**

MR的shuffle 过程每一个task 会产生多个小文件，task之间的文件无法共用；Spark 的shuffle过程会合并小文件，保持task和file是一对一，来精简小文件的数量。

**5，数据**

MR的数据多是hdfs，一对Map和Reduce 与其他MR是独立的，上下游执行阶段是没有血缘记录的；Spark的数据是RDD，多MR形式来共享数据，构建了一个DAG（有向无环图），上下游执行阶段是有血缘记录的，减少了重复拉取数据的成本。

**6，资源申请粒度**

MapReduce是细粒度每一个task去独自做资源申请，Spark是粗粒度是一个整体job来资源申请。



##### RDD简介

RDD的全称是：Resilient Distributed Dataset （弹性分布式数据集），RDD 具有以下几个属性。

- 只读：不能修改，只能通过转换操作生成新的 RDD。
- 分布式：可以分布在多台机器上进行并行处理。
- 弹性：计算过程中内存不够时它会和磁盘进行数据交换。
- 基于内存：可以全部或部分缓存在内存中，在多次计算间重用。



每个RDD的内部，有5个主要特性：

1. A list of partitions （一个分区列表，可以获取所有的数据分区）
2. A function for computing each split（对给定的分区内的数据进行计算的function）
3. A list of dependencies on other RDDs （一个RDD所依赖的父RDD列表）
4. Optionally, a Partitioner for key-value RDDs （可选：如何进行K-V的RDD分区）
5. Optionally, a list of preferred locations to compute each split on（可选：数据做运算时最优的地址，即数据本地性）



RDD 的分区及分区与工作结点（Worker Node）的分布关系:

![partions](.\image\partions.jpg)



RDD 实质上是一种更为通用的迭代并行计算框架，用户可以显示控制计算的中间结果，然后将其自由运用于之后的计算。在大数据实际应用开发中存在许多迭代算法，如机器学习、图算法等，和交互式数据挖掘工具。这些应用场景的共同之处是在不同计算阶段之间会重用中间结果，即一个阶段的输出结果会作为下一个阶段的输入。



##### RDD操作

Spark官方给做了一个分类，分为Transformations 与 Actions；字面解释为转换与动作。

常用的一些转化算子：

| 转换                           | 含义                                                         |
| ------------------------------ | ------------------------------------------------------------ |
| map(func)                      | 返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成 |
| filter(func)                   | 返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成。 |
| flatMap(func)                  | 类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素） |
| mapPartitions(func)            | 类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] => Iterator[U] |
| groupByKey([numTasks])         | 在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD        |
| reduceByKey(func, [numTasks])  | 在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置 |
| join(otherDataset, [numTasks]) | 在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD |

常用的一些Action算子

| 动作                   | 含义                                                         |
| ---------------------- | ------------------------------------------------------------ |
| collect()              | 在驱动程序中，以数组的形式返回数据集的所有元素               |
| count()                | 返回RDD的元素个数                                            |
| take(*n*)              | 返回一个由数据集的前n个元素组成的数组                        |
| saveAsTextFile(*path*) | 将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本 |
| foreach(*func*)        | 在数据集的每一个元素上，运行函数func进行更新。               |



#### 4. 大数据常用框架简介

1. 资源调度层

##### Yarn：

~~~
在古老的 Hadoop1.0 中，MapReduce 的 JobTracker 负责了太多的工作，包括资源调度，管理众多的 TaskTracker 等工作。这自然是不合理的，于是 Hadoop 在 1.0 到 2.0 的升级过程中，便将 JobTracker 的资源调度工作独立了出来，而这一改动，直接让 Hadoop 成为大数据中最稳固的那一块基石。，而这个独立出来的资源管理框架，就是 Yarn。
~~~

2. 计算层

##### Spark、Mapreduce。

##### Spark Streaming  & Storm & Flink 流式处理

~~~~
storm 和 Flink 都是真正意义上的流计算框架，但 Spark Streaming 只是将数据流进行极小粒度的拆分，拆分为多个批处理，使得其能够得到接近于流处理的效果，但其本质上还是批处理（或微批处理）。
~~~~

3. 存储层

##### HDFS

~~~
是一个分布式文件系统。它是谷歌的GFS提出之后出现的另外一种文件系统。它有一定高度的容错性，而且提供了高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS 提供了一个高度容错性和高吞吐量的海量数据存储解决方案
~~~



##### Hive、SparkOnHive

~~~
Hive是一种用类SQL语句来协助读写、管理那些存储在分布式存储系统上大数据集的数据仓库软件。
Hive最大的特点是通过类SQL来分析大数据，而避免了写MapReduce程序来分析数据，这样使得分析数据更容易。

特点：
1. 数据是存储在HDFS上的，Hive本身并不提供数据的存储功能

2. Hive是将数据映射成数据库和一张张的表，库和表的元数据信息一般存在关系型数据库上（比如MySQL）。

3. 数据存储方面：它能够存储很大的数据集，并且对数据完整性、格式要求并不严格。

4. 数据处理方面：因为Hive语句最终会生成MapReduce任务去计算，所以不适用于实时计算的场景，它适用于离线分析。
~~~



##### HBase

~~~
HBase 是一种构建在 HDFS 之上的分布式、面向列（但不是列存储）的存储系统。
在需要实时读写、随机访问超大规模数据集时，可以使用 HBase。
HBase 可以通过线性方式增加节点来进行扩展。HBase 不是关系型数据库，自身不支持 SQL 查询引擎，HBase 适合将大而稀疏的表放在分布式集群上。
HBase 是 Google Bigtable 的开源实现，利用 Hadoop HDFS 作为其文件存储系统；利用 Hadoop MapReduce（或其他计算引擎） 来处理 HBase 中的海量数据；使用 Zookeeper 作为协同服务。
~~~

HBase 的特点

- 容量大：一个表可以有上亿行，上百万列
- 面向列：面向列的存储（但不是列存储，参考 HBase 数据存储）和权限控制，支持列的独立检索
- 稀疏性：对于为空（NULL）的列，并不占用存储空间，因此，表可以设计的非常稀疏
- 无模式：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，不同的行可以有不同的列
- 数据多版本：每个单元格（Cell）中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳
- 数据类型单一：HBase 中的数据都是字符串（存入字节），没有类型
- 随机查询：针对 Rowkey 的查询能够达到毫秒级别

